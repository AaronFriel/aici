// For format details, see https://aka.ms/devcontainer.json
{
	"name": "AICI with CUDA and vLLM (experimental)",
	"build": {
		"dockerfile": "../Dockerfile-vllm",
		"context": ".."
	},
	"runArgs": [
		"--privileged",
		"--gpus",
		"all",
		"--shm-size=8g"
	],
	"mounts": [
		"source=profile,target=/root,type=volume",
		"target=/root/.vscode-server,type=volume"
	],
	"customizations": {
		"vscode": {
			"extensions": [
				"ms-python.python",
				"ms-python.black-formatter",
				"1YiB.rust-bundle",
				"dtsvet.vscode-wasm",
				"ms-vscode.cpptools",
				"esbenp.prettier-vscode",
				"streetsidesoftware.code-spell-checker",
				"GitHub.copilot"
			]
		}
	},
	"forwardPorts": [
		8080
	]
}