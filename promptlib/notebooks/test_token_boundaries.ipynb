{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing completion errors based on token boundary issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.insert(0, 'c:\\\\users\\\\emrek\\\\source\\\\guidance\\\\prompt-plan\\\\promptlib\\\\')\n",
    "sys.path.insert(0, '/workspaces/aici/promptlib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptlib import PromptNode\n",
    "from promptlib import set_model, append, gen, choose, begin, end\n",
    "from promptlib.models import LLM, TransformersLLM\n",
    "from promptlib.endpoints import AICI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using AICI server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = AICI(base_url=\"http://127.0.0.1:8080/v1/\", wasm_runner_path=\"/workspaces/aici/aici_ast_runner/target/opt.wasm\")\n",
    "\n",
    "endpoint = PromptNode().set_endpoint(ep)\n",
    "\n",
    "pn = endpoint.append(\"Please answer the following questions:\\n Q: Who is the president of the USA?\\n A: Michal Moskal\").gen(max_tokens=10)             \\\n",
    "    .append(\"\\nQ: And who is the vice president?\\n A:\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http://\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http:/\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http:\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n htt\").gen(max_tokens=20)\n",
    "\n",
    "endpoint.run(pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results look like:\n",
    "```\n",
    "upload module... 2713kB -> 2604kB id:09d17084\n",
    "Please answer the following questions:\n",
    " Q: Who is the president of the USA?\n",
    " A: Michal Moskal.\n",
    "Q: And who is the vice president?\n",
    " A: Barack Obama.\n",
    "Please give a url with evidence\n",
    " http://www.whitehouse.gov/briefing-room/presidential-press-con\n",
    "Please give a url with evidence\n",
    " http:/www.whitehouse.gov/briefing-room/presidential-press-con\n",
    "Please give a url with evidence\n",
    " http:www.whitehouse.gov/briefing-room/presidential-press-con\n",
    "Please give a url with evidence\n",
    " http://www.whitehouse.gov/briefing-room/presidential-press-\n",
    "Please give a url with evidence\n",
    " httpp://www.whitehouse.gov/briefing-room/presidential-press\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using OpenAI completions API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptlib.models import OpenAILLM\n",
    "\n",
    "organization = None\n",
    "api_key = None\n",
    "\n",
    "openai_completion_model = OpenAILLM(\"text-davinci-003\", organization, api_key)\n",
    "\n",
    "model = PromptNode().set_model(openai_completion_model)\n",
    "\n",
    "pn = model.append(\"Please answer the following questions:\\n Q: Who is the president of the USA?\\n A: Michal Moskal\").gen(max_tokens=10)             \\\n",
    "    .append(\"\\nQ: And who is the vice president?\\n A:\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http://\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http:/\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http:\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n http\").gen(max_tokens=20) \\\n",
    "    .append(\"\\nPlease give a url with evidence\\n htt\").gen(max_tokens=20)\n",
    "\n",
    "txt = pn.get_all_text()\n",
    "\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results look like:\n",
    "```\n",
    "Please answer the following questions:\n",
    " Q: Who is the president of the USA?\n",
    " A: Michal Moskaluk is the President of the United States.\n",
    "Q: And who is the vice president?\n",
    " A: Kamala Harris is the Vice President of the United States.\n",
    "Please give a url with evidence\n",
    " http://www.whitehouse.gov/briefing-room/vice-president/\n",
    "Please give a url with evidence\n",
    " http:/www.whitehouse.gov/people/mike-pence/\n",
    "Please give a url with evidence\n",
    " http:www.whitehouse.gov/briefing-room/presidential-biographies/president\n",
    "Please give a url with evidence\n",
    " http://www.presidency.ucsb.edu/biographies/mike-pence\n",
    "Please give a url with evidence\n",
    " htttps://www.whitehouse.gov/briefing-room/vice-president/\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
