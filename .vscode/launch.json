{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "vLLM server",
            "type": "debugpy",
            "request": "launch",
            "module": "pyaici.vllm_server",
            "env": {
                "RUST_LOG": "info,tokenizers=error,aicirt=info",
                "RUST_BACKTRACE": "1",
                "PYTHONPATH": "${workspaceFolder}/py:${workspaceFolder}/py/vllm"
            },
            "args": [
                "--enforce-eager",
                "--use-v2-block-manager",
                "--enable-chunked-prefill",
                "--served-model-name=model",
                "--aici-rt",
                "./target/release/aicirt",
                "-A--wasm-timer-resolution-us=10",
                "--model",
                "microsoft/Phi-3-mini-128k-instruct",
                "--trust-remote-code",
                "--port",
                "4242",
                "--host",
                "127.0.0.1",
                "--trust-remote-code"
            ]
        },
        {
            "type": "lldb",
            "request": "launch",
            "name": "rllm-llamacpp phi",
            "cwd": "rllm/rllm-llamacpp",
            "preLaunchTask": "rllm-llamacpp: build",
            "program": "${workspaceFolder}/target/debug/rllm-llamacpp",
            "env": {
                "RUST_LOG": "info,tokenizers=error,rllm=trace,aicirt=info,llama_cpp_low=trace"
            },
            "args": [
                "--verbose",
                "--aicirt=${workspaceFolder}/target/release/aicirt",
                "--model=https://huggingface.co/TheBloke/phi-2-GGUF/blob/main/phi-2.Q8_0.gguf",
                "--gpu-layers=100"
            ]
        }
    ]
}